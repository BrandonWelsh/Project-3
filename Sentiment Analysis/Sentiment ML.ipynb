{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('../Resources/train_2.csv', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv('../Resources/test_2.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   text              27480 non-null  object \n",
      " 1   selected_text     27480 non-null  object \n",
      " 2   Time of Tweet     27481 non-null  object \n",
      " 3   Age of User       27481 non-null  object \n",
      " 4   Country           27481 non-null  object \n",
      " 5   Population -2020  27481 non-null  int64  \n",
      " 6   Land Area (Km²)   27481 non-null  float64\n",
      " 7   Density (P/Km²)   27481 non-null  int64  \n",
      " 8   sentiment         27481 non-null  object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3534 entries, 0 to 3533\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   text              3534 non-null   object \n",
      " 1   Time of Tweet     3534 non-null   object \n",
      " 2   Age of User       3534 non-null   object \n",
      " 3   Country           3534 non-null   object \n",
      " 4   Population -2020  3534 non-null   int64  \n",
      " 5   Land Area (Km²)   3534 non-null   float64\n",
      " 6   Density (P/Km²)   3534 non-null   int64  \n",
      " 7   sentiment         3534 non-null   object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 221.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'text' is the feature column and 'sentiment' is the target\n",
    "X_train, y_train = train_df['text'].fillna(''), train_df['sentiment']\n",
    "X_test, y_test = test_df['text'].fillna(''), test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the encoder and transform the target columns to numerical labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and Vectorize text data for the logistic regression model\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the TF-IDF features\n",
    "scaler = StandardScaler(with_mean=False)  # Set with_mean=False for sparse data compatibility\n",
    "X_train_tfidf_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf_scaled = scaler.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6581777023203169\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model with the scaled data\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf_scaled, y_train_encoded) \n",
    "lr_predictions = lr_model.predict(X_test_tfidf_scaled)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_encoded, lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[650, 288,  63],\n",
       "       [271, 930, 229],\n",
       "       [ 75, 282, 746]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusuion matrix for the logistic regression model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_encoded, lr_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1001\n",
      "           1       0.62      0.65      0.63      1430\n",
      "           2       0.72      0.68      0.70      1103\n",
      "\n",
      "    accuracy                           0.66      3534\n",
      "   macro avg       0.66      0.66      0.66      3534\n",
      "weighted avg       0.66      0.66      0.66      3534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, and F1-Score for the logistic regression model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_encoded, lr_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained Logistic Regression model\n",
    "#lr_model.save('logistic_regression_model.keras')\n",
    "joblib.dump(lr_model, 'logistic_regression_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6870401810979061\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest model with the scaled data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train_tfidf_scaled, y_train_encoded)\n",
    "rf_predictions = rf_model.predict(X_test_tfidf_scaled)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test_encoded, rf_predictions))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 561,  395,   45],\n",
       "       [ 168, 1092,  170],\n",
       "       [  42,  286,  775]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for the random forest model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_encoded, rf_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.63      1001\n",
      "           1       0.62      0.76      0.68      1430\n",
      "           2       0.78      0.70      0.74      1103\n",
      "\n",
      "    accuracy                           0.69      3534\n",
      "   macro avg       0.71      0.68      0.69      3534\n",
      "weighted avg       0.70      0.69      0.69      3534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, and F1-Score for the random forest model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_encoded, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained Random Forest model\n",
    "#lr_model.save('random_forest_model.keras')\n",
    "joblib.dump(rf_model, 'random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.5721561969439728\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes model with the scaled data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf_scaled, y_train_encoded)\n",
    "nb_predictions = nb_model.predict(X_test_tfidf_scaled)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test_encoded, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[617, 267, 117],\n",
       "       [366, 705, 359],\n",
       "       [125, 278, 700]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix for the Navie Bayes model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_encoded, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.63      1001\n",
      "           1       0.62      0.76      0.68      1430\n",
      "           2       0.78      0.70      0.74      1103\n",
      "\n",
      "    accuracy                           0.69      3534\n",
      "   macro avg       0.71      0.68      0.69      3534\n",
      "weighted avg       0.70      0.69      0.69      3534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, and F1-Score for the Navie Bayes model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_encoded, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_model.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained Naive Bayes model\n",
    "#lr_model.save('naive_bayes_model.keras')\n",
    "joblib.dump(nb_model, 'naive_bayes_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CNN\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "maxlen = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model-building function for the tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=50),\n",
    "    Conv1D(\n",
    "        filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('kernel_size', values=[3, 5, 7]),\n",
    "        activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(units=hp.Int('dense_units', min_value=10, max_value=100, step=10), activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=hp.Choice('optimizer', ['adam']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\sentiment_analysis\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='sentiment_analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the search with encoded labels\n",
    "tuner.search(X_train_pad, y_train_encoded, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: my_dir\\sentiment_analysis\\trial_3\\build_config.json : The system cannot find the file specified.\r\n; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rac06\\anaconda3\\envs\\proj3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:400\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rac06\\anaconda3\\envs\\proj3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\rac06\\anaconda3\\envs\\proj3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\rac06\\anaconda3\\envs\\proj3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:325\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# Build model to create the weights.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m    324\u001b[0m     model\u001b[38;5;241m.\u001b[39mbuild_from_config(\n\u001b[1;32m--> 325\u001b[0m         \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_build_config_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     )\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Reload best checkpoint.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n",
      "File \u001b[1;32mc:\\Users\\rac06\\anaconda3\\envs\\proj3\\lib\\site-packages\\keras_tuner\\src\\utils.py:107\u001b[0m, in \u001b[0;36mload_json\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load json from file.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    A Python object.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mFile(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 107\u001b[0m     obj_str \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(obj_str)\n",
      "File \u001b[1;32mc:\\Users\\rac06\\anaconda3\\envs\\proj3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:116\u001b[0m, in \u001b[0;36mFileIO.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    105\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the contents of a file as a string.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m  Starts reading from current position in file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    string if in string (regular) mode.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preread_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    118\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\rac06\\anaconda3\\envs\\proj3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:77\u001b[0m, in \u001b[0;36mFileIO._preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_check_passed:\n\u001b[0;32m     75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mPermissionDeniedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt open for reading\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_buf \u001b[38;5;241m=\u001b[39m \u001b[43m_pywrap_file_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: my_dir\\sentiment_analysis\\trial_3\\build_config.json : The system cannot find the file specified.\r\n; No such file or directory"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best CNN model\n",
    "best_model.save('best_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 2ms/step - loss: -3051019776.0000 - accuracy: 0.4046\n",
      "CNN with Tuner Accuracy: 0.40464064478874207\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model with encoded labels\n",
    "_, accuracy = best_model.evaluate(X_test_pad, y_test_encoded)\n",
    "print(\"CNN with Tuner Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
