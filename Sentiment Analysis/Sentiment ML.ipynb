{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from keras) (13.7.0)\n",
      "Requirement already satisfied: namex in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from keras) (0.1.8)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\omar\\anaconda3\\envs\\bootcamp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import MaxPooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('../Resources/train_2.csv', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv('../Resources/test_2.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6590265987549518\n",
      "Reloading Tuner from my_dir\\sentiment_analysis\\tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omar\\anaconda3\\envs\\bootcamp\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 3 objects could not be loaded. Example error message for object <Conv1D name=conv1d_1, built=True>:\n\nLayer 'conv1d_1' expected 2 variables, but received 0 variables during loading. Expected: ['kernel', 'bias']\n\nList of objects that could not be loaded:\n[<Conv1D name=conv1d_1, built=True>, <Conv1D name=conv1d_2, built=True>, <Dense name=dense, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train_pad, y_train_encoded, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Get the best model\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Evaluate the best model with encoded labels\u001b[39;00m\n\u001b[0;32m     85\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mevaluate(X_test_pad, y_test_encoded)\n",
      "File \u001b[1;32mc:\\Users\\Omar\\anaconda3\\envs\\bootcamp\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:400\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Omar\\anaconda3\\envs\\bootcamp\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbest_trials\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\Omar\\anaconda3\\envs\\bootcamp\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\Omar\\anaconda3\\envs\\bootcamp\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:331\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Reload best checkpoint.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[1;32m--> 331\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_checkpoint_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Omar\\anaconda3\\envs\\bootcamp\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Omar\\anaconda3\\envs\\bootcamp\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:273\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    271\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 3 objects could not be loaded. Example error message for object <Conv1D name=conv1d_1, built=True>:\n\nLayer 'conv1d_1' expected 2 variables, but received 0 variables during loading. Expected: ['kernel', 'bias']\n\nList of objects that could not be loaded:\n[<Conv1D name=conv1d_1, built=True>, <Conv1D name=conv1d_2, built=True>, <Dense name=dense, built=True>]"
     ]
    }
   ],
   "source": [
    "# Assuming 'text' is the feature column and 'sentiment' is the target\n",
    "X_train, y_train = train_df['text'].fillna(''), train_df['sentiment']\n",
    "X_test, y_test = test_df['text'].fillna(''), test_df['sentiment']\n",
    "\n",
    "# Instantiate the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the target columns to numerical labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Preprocess and Vectorize text data for the logistic regression model\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# Scale the TF-IDF features\n",
    "scaler = StandardScaler(with_mean=False)  # Set with_mean=False for sparse data compatibility\n",
    "X_train_tfidf_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf_scaled = scaler.transform(X_test_tfidf)\n",
    "\n",
    "# Train a Logistic Regression model with the scaled data\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf_scaled, y_train_encoded) \n",
    "lr_predictions = lr_model.predict(X_test_tfidf_scaled)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_encoded, lr_predictions))\n",
    "\n",
    "# Prepare data for CNN\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "maxlen = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)\n",
    "\n",
    "# Define a model-building function for the tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=50),\n",
    "    Conv1D(\n",
    "        filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('kernel_size', values=[3, 5, 7]),\n",
    "        activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(units=hp.Int('dense_units', min_value=10, max_value=100, step=10), activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=hp.Choice('optimizer', ['adam']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='sentiment_analysis'\n",
    ")\n",
    "\n",
    "# Execute the search with encoded labels\n",
    "tuner.search(X_train_pad, y_train_encoded, epochs=5, validation_split=0.1)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model with encoded labels\n",
    "_, accuracy = best_model.evaluate(X_test_pad, y_test_encoded)\n",
    "print(\"CNN with Tuner Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
