# Project 3, Group 4
- Brandon Welsh
- Joe Timmons
- Omar Hassanein
- Raymond Conley

April 2024

Due date: April 22nd, 2024

## Program Goals
The goal of our project is to produce a neural network trained on Twitter sentiment analysis data, which is capable of reading the content of a tweet provided to it and recognize the sentiment of that tweet as being either positive, neutral, or negative. It is able to accept user input for this tweet in a Streamlit interface, and display the rating of the tweet. Additionally, work was performed to develop an AI which could read the content of the tweet and provide an emoji which is most closely related to the content of the tweet, defaulting to a simple smile, frown, or neutral face (based on the sentiment score of the tweet) if it could not determine a suitable emoji.

## Data Source
Tweet data source: https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset

Streamlit UI: https://streamlit.io/ [USE GRADIO IF WE CAN'T GET STREAMLIT TO WORK]

## Dependencies/Setup Instructions
NOTE: Complete this part of the write-up AFTER the program is complete and all dependencies are accounted for

Pip install all required libraries before running the following cell.

Run the following cell in the juptyer notebook:
  Import BLANK as BLANK
  Import BLANK as BLANK
  etc...

## How to use
TODO

## Team Member Responsibilities
Brandon Welsh: Performed research on the image recognition portion of the project before pivoting that over to create an emoji bot based on the sentiment of the tweet. [I will add more to this]

Joe Timmons:

Omar Hassanein:

Raymond Conley:

## Team Member Analysis
Brandon Welsh: My interpretation of the results of this project is... [2-3 paragraphs per person]

Joe Timmons: 

Omar Hassanein: 

Raymond Conley: 

## Resources Utilized
TODO, KEEP ADDING TO THIS

Python, Jupyter Notebooks

## Bugs
TODO, LIST BUGS AS THEY SHOW UP

## For Future Research
The emoji functionality was an add-on to the project and was done in place of the original plan. Our original plan was to take a sample (about 20) of tweets, run them through a free AI image generator (DALL-E 3 or equivalent), and then feed these images to a convolutional neural network trained on image sentiment, in order to determine the sentiment of the tweet based on the image generated by AI. We would then be able to compare the results of this model with our text-based sentiment analysis bot and see if one or both (or neither) was able to make an accurate prediction of the sentiment of the Tweet content. Unfortunately, our hubris was larger than the technology required to pull this off. The biggest problem was obtaining pre-labeled image sentiment data to use to train the CNN. I (Brandon Welsh) worked with this dataset for a while: [https://data.world/crowdflower/image-sentiment-polarity]. It contains approximately 16,000 random images which have been labeled into one of five categories: highly positive, positive, neutral, negative, and highly negative. The biggest problem with the dataset is that it is far too small. Image data is exceedingly complex, and anything an AI could generate would push imagination to its limit. While this dataset was good, it is far from complete. We would need millions of similar images in order to train an AI on the complexities of human emotion evoked by images. Additionally, sentiment from image data, like art, is subjective rather than objective. Take a random image from that dataset for an example. It was a picture of a run down building covered in grafitti, and was labeled "negative". However, this building can carry a different sentiment based on the viewer. While some may perceive it as being dangerous, and worthy of the "negative" score, others may appreciate the stark beauty of the grafitti on an urban canvas, and they would rate it as "positive". An AI, which carries no feelings or emotions, would have to be taught to recognize numerous items, artifacts, and objects in the image, and understand the context behind why people may score it differently. Training AI to recognize and understand context, as well as make reasonable assumptions to understand and emulate human emotion is a very important subject for areas like marketing research, political science, sociology and humanities studies. Further research needs to be taken on this subject, and this (as we soon realized) is far beyond the scope of our initial project.

## Update Log
April 10: Created Github Repository, complete with gitignore and README, shared it with everyone.

April 11: Added Omar's initial data cleaning, collection, and analysis to the repo.

April 14: README update, work done towards the emoji bot.
