{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\AppData\\Local\\Temp\\ipykernel_9256\\3612248984.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.models import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('../Resources/train_2.csv', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv('../Resources/test_2.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   text              27480 non-null  object \n",
      " 1   selected_text     27480 non-null  object \n",
      " 2   Time of Tweet     27481 non-null  object \n",
      " 3   Age of User       27481 non-null  object \n",
      " 4   Country           27481 non-null  object \n",
      " 5   Population -2020  27481 non-null  int64  \n",
      " 6   Land Area (Km²)   27481 non-null  float64\n",
      " 7   Density (P/Km²)   27481 non-null  int64  \n",
      " 8   sentiment         27481 non-null  object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3534 entries, 0 to 3533\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   text              3534 non-null   object \n",
      " 1   Time of Tweet     3534 non-null   object \n",
      " 2   Age of User       3534 non-null   object \n",
      " 3   Country           3534 non-null   object \n",
      " 4   Population -2020  3534 non-null   int64  \n",
      " 5   Land Area (Km²)   3534 non-null   float64\n",
      " 6   Density (P/Km²)   3534 non-null   int64  \n",
      " 7   sentiment         3534 non-null   object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 221.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'text' is the feature column and 'sentiment' is the target\n",
    "X_train, y_train = train_df['text'].fillna(''), train_df['sentiment']\n",
    "X_test, y_test = test_df['text'].fillna(''), test_df['sentiment']\n",
    "\n",
    "# Instantiate the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the target columns to numerical labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Preprocess and Vectorize text data for the logistic regression model\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# Scale the TF-IDF features\n",
    "scaler = StandardScaler(with_mean=False)  # Set with_mean=False for sparse data compatibility\n",
    "X_train_tfidf_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf_scaled = scaler.transform(X_test_tfidf)\n",
    "\n",
    "# Train a Logistic Regression model with the scaled data\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf_scaled, y_train_encoded) \n",
    "lr_predictions = lr_model.predict(X_test_tfidf_scaled)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_encoded, lr_predictions))\n",
    "\n",
    "# Save the trained Logistic Regression model\n",
    "lr_model.save('logistic_regression_model.keras')\n",
    "\n",
    "# Prepare data for CNN\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "maxlen = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)\n",
    "\n",
    "# Define a model-building function for the tuner\n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=50),\n",
    "    Conv1D(\n",
    "        filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('kernel_size', values=[3, 5, 7]),\n",
    "        activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        activation='relu'\n",
    "    ),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(units=hp.Int('dense_units', min_value=10, max_value=100, step=10), activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=hp.Choice('optimizer', ['adam']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='sentiment_analysis'\n",
    ")\n",
    "\n",
    "# Execute the search with encoded labels\n",
    "tuner.search(X_train_pad, y_train_encoded, epochs=5, validation_split=0.1)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Save the best CNN model\n",
    "best_model.save('best_cnn_model.keras')\n",
    "\n",
    "# Evaluate the best model with encoded labels\n",
    "_, accuracy = best_model.evaluate(X_test_pad, y_test_encoded)\n",
    "print(\"CNN with Tuner Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
